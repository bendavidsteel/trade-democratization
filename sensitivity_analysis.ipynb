{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sensitivity_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMIuFymfoNmt0+FOG/VQnWc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bendavidsteel/trade-democratization/blob/master/sensitivity_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpOyBeiTVslV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install torch-scatter==2.0.4+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n",
        "!pip install torch-sparse==0.6.5+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n",
        "!pip install torch-cluster==1.5.5+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n",
        "!pip install torch-spline-conv==1.2.0+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n",
        "!pip install torch-geometric"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuJLrL43V2et",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch_geometric as geo\n",
        "import tqdm\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJbWkt3hV32J",
        "colab_type": "text"
      },
      "source": [
        "In this notebook I'd like to start doing some sensitivity analysis of the model, i.e. seeing if it reacts in the way one would expect to changes in bilateral relationships."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDu8xE0YV3SM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RecurGraphNet(torch.nn.Module):\n",
        "    def __init__(self, num_node_features, num_edge_features, num_output_features):\n",
        "        super().__init__()\n",
        "\n",
        "        conv_layer_size = 32\n",
        "        lstm_layer_size = 32\n",
        "\n",
        "        # graph convolutional layer to create graph representation\n",
        "        conv_lin = torch.nn.Linear(num_edge_features, num_node_features * conv_layer_size)\n",
        "        self.conv = geo.nn.NNConv(num_node_features, conv_layer_size, conv_lin)\n",
        "\n",
        "        # lstm to learn sequential patterns\n",
        "        self.lstm = torch.nn.LSTM(conv_layer_size, lstm_layer_size, dropout=0.5)\n",
        "\n",
        "        # initial trainable hidden state for lstm\n",
        "        self.lstm_h_s = torch.nn.Linear(num_output_features, lstm_layer_size)\n",
        "        self.lstm_c_s = torch.nn.Linear(num_output_features, lstm_layer_size)\n",
        "\n",
        "        # final linear layer to allow full expressivity for regression after tanh activation in lstm\n",
        "        self.final_linear = torch.nn.Linear(lstm_layer_size, num_output_features)\n",
        "\n",
        "    def forward(self, input):\n",
        "        initial, sequence = input.initial, input.sequence\n",
        "        \n",
        "        # create graph representation\n",
        "        graph_collection = []\n",
        "        for idx in range(len(sequence)):\n",
        "            x, edge_index, edge_attr = sequence[idx].x, sequence[idx].edge_index, sequence[idx].edge_attr\n",
        "            graph_step = torch.nn.functional.relu(self.conv(x, edge_index, edge_attr))\n",
        "            graph_collection.append(graph_step)\n",
        "        # provide graph representations as sequence to lstm\n",
        "        graph_series = torch.stack(graph_collection)\n",
        "\n",
        "        # recurrent stage\n",
        "        # initial state of lstm is representation of target prior to this sequence\n",
        "        lstm_output, _ = self.lstm(graph_series, (self.lstm_h_s(initial).unsqueeze(0), self.lstm_c_s(initial).unsqueeze(0)))\n",
        "\n",
        "        # final activation is relu as this is for regression and the metrics of this dataset are all positive\n",
        "        return self.final_linear(lstm_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epGcgnstZbQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Sequence():\n",
        "    def __init__(self, initial, sequence, missing_mask, target):\n",
        "        self.initial = initial\n",
        "        self.sequence = sequence\n",
        "        self.missing_mask = missing_mask\n",
        "        self.target = target\n",
        "\n",
        "    def to(self, device):\n",
        "        self.initial = self.initial.to(device)\n",
        "        self.missing_mask = self.missing_mask.to(device)\n",
        "        self.target = self.target.to(device)\n",
        "        for idx in range(len(self.sequence)):\n",
        "            self.sequence[idx] = self.sequence[idx].to(device)\n",
        "        return self"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFdjhS8dXztv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@torch.no_grad()\n",
        "def get_predictions(recur_seq, non_recur_seq):\n",
        "    # get prediction of recurrent model\n",
        "    recur_seq = recur_seq.to(device)\n",
        "    recur_prediction = recur_model(recur_seq)\n",
        "\n",
        "    # first data object in this sequence has prior demo conditions\n",
        "    year_preds = []\n",
        "    for idx in range(len(non_recur_seq)):\n",
        "        data = non_recur_seq[idx].to(device)\n",
        "        pred = non_recur_model(data)\n",
        "        year_preds.append(pred)\n",
        "\n",
        "        if idx + 1 < len(non_recur_seq):\n",
        "            non_recur_seq[idx + 1].x[:, 2] = pred.squeeze(-1)\n",
        "\n",
        "    non_recur_prediction = torch.stack(year_preds)\n",
        "\n",
        "    return recur_prediction, non_recur_prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOTrcrkeX49I",
        "colab_type": "text"
      },
      "source": [
        "Lets create a simple scenario with three countries, with distinct democratization differences, and see how changes in their relationships affects their democratic tendencies over time. Lets call them A-Io, Thu and Anarres."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhG4Sih-X1JW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Anarres\n",
        "anarres_initial = 0.95\n",
        "# A-Io\n",
        "aio_initial = 0.55\n",
        "# Thu\n",
        "thu_initial = 0.25"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}