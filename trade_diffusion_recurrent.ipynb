{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trade_diffusion_recurrent.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP3mvKTgWrWXqpkzYAKi15P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bendavidsteel/trade-democratization/blob/master/trade_diffusion_recurrent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Oxcg4dGh326",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install torch-scatter==2.0.4+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n",
        "!pip install torch-sparse==0.6.5+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n",
        "!pip install torch-cluster==1.5.5+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n",
        "!pip install torch-spline-conv==1.2.0+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n",
        "!pip install torch-geometric"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AflAeT2iRDk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "import math\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch_geometric as geo\n",
        "import tqdm\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_WwOarnipJi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_mapping(vdem_nodes, tradhist_timevar):   \n",
        "\n",
        "    vdem_country_codes = set(vdem_nodes['country_text_id'].unique())\n",
        "    tradhist_country_codes = set(tradhist_timevar['iso_o'].unique())\n",
        "    shared_codes = vdem_country_codes & tradhist_country_codes\n",
        "\n",
        "    mapped_codes = [['RUS', 'USSR'], ['YEM', 'ADEN'], ['CAF', 'AOFAEF', 'FRAAEF'], ['TCD', 'AOFAEF', 'FRAAEF'], ['COD', 'AOFAEF', 'FRAAEF'], ['HRV', 'AUTHUN', 'YUG'], ['SVK', 'CZSK', 'AUTHUN'], \n",
        "                ['SVN', 'AUTHUN', 'YUG'], ['UKR', 'AUTHUN', 'USSR'], ['ALB', 'AUTHUN'], ['BIH', 'AUTHUN', 'YUG'], ['MNE', 'AUTHUN', 'YUG'], ['CAN', 'CANPRINCED', 'CANQBCONT', 'NFLD'], \n",
        "                ['CZE', 'CZSK', 'AUTHUN'], ['DDR', 'EDEU'], ['MYS', 'FEDMYS', 'UNFEDMYS', 'GBRBORNEO'], ['BFA', 'FRAAOF'], ['GNQ', 'FRAAOF'], ['LUX', 'ZOLL'], \n",
        "                ['ZZB', 'ZANZ', 'GBRAFRI'], ['ZAF', 'ZAFTRA', 'ZAFORA', 'ZAFNAT', 'ZAPCAF', 'GBRAFRI'], ['MKD', 'YUG'], ['SRB', 'YUG'], ['POL', 'USSR'], ['COM', 'MYT'], ['ROU', 'ROM'], \n",
        "                ['MWI', 'RHOD', 'GBRAFRI'], ['ZMB', 'RHOD', 'GBRAFRI'], ['ZWE', 'RHOD', 'GBRAFRI'], ['SGP', 'STRAITS'], ['DEU', 'WDEU'], ['SML', 'GBRSOM', 'ITASOM'], ['GBR', 'ULSTER'], \n",
        "                ['RWA', 'RWABDI'], ['SOM', 'ITASOM'], ['MAR', 'MARESP'], ['FRA', 'OLDENB'], ['DNK', 'SCHLES'], ['LBN', 'SYRLBN', 'OTTO'], ['SYR', 'SYRLBN'], ['CYP', 'OTTO', 'GBRMEDI'], \n",
        "                ['TUR', 'OTTO'], ['STP', 'PRTAFRI'], ['AGO', 'PRTAFRI'], ['MOZ', 'PRTAFRI'], ['GNB', 'PRTWAFRI'], ['KHM', 'INDOCHI'], ['LAO', 'INDOCHI'], ['VNM', 'INDOCHI'], \n",
        "                ['ERI', 'ITAEAFRI', 'GBRAFRI'], ['TTO', 'GBRWINDIES'], ['SLE', 'GBRWAFRI'], ['GMB', 'GBRWAFRI'], ['TGO', 'GBRWAFRI'], ['EGY', 'OTTO'],\n",
        "                ['PNG', 'GBRPAPUA'], ['MLT', 'GBRMEDI'], ['BGD', 'GBRIND'], ['BTN', 'GBRIND'], ['IND', 'GBRIND'], ['MDV', 'GBRIND'], ['NPL', 'GBRIND'], ['PAK', 'GBRIND'], \n",
        "                ['LKA', 'GBRIND'], ['CMR', 'GBRAFRI', 'FRAAFRI'], ['KEN', 'GBRAFRI'], ['SYC', 'GBRAFRI'], ['SDN', 'GBRAFRI'], ['UGA', 'GBRAFRI'], ['LSO', 'GBRAFRI'], \n",
        "                ['SWZ', 'GBRAFRI']]\n",
        "\n",
        "    # validate my matches\n",
        "    code_count = {}\n",
        "    for codes in mapped_codes:\n",
        "        matched_to_vdem = 0\n",
        "        for code in codes:\n",
        "            if len(code) == 3:\n",
        "                if code in vdem_country_codes:\n",
        "                    if code in code_count:\n",
        "                        code_count[code] += 1\n",
        "                    else:\n",
        "                        code_count[code] = 1\n",
        "                    matched_to_vdem += 1\n",
        "\n",
        "        if matched_to_vdem == 0:\n",
        "            raise ValueError(\"{} country code set matched to no VDem node\".format(codes))\n",
        "        elif matched_to_vdem > 1:\n",
        "            raise ValueError(\"{} country code set matched to more than one VDem node\".format(codes))\n",
        "\n",
        "        if codes[0] not in vdem_country_codes:\n",
        "            raise ValueError(\"VDem code should be first in list {}.\".format(codes))\n",
        "\n",
        "    for code in code_count:\n",
        "        if code_count[code] != 1:\n",
        "            raise ValueError(\"VDem code {} matched to more than one country code set\".format(code))\n",
        "\n",
        "    for code in shared_codes:\n",
        "        if code not in code_count:\n",
        "            mapped_codes.append([code])\n",
        "\n",
        "    return mapped_codes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YegMqC81x7wq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Sequence():\n",
        "    def __init__(self, initial, sequence, missing_mask):\n",
        "        self.initial = initial\n",
        "        self.sequence = sequence\n",
        "        self.missing_mask = missing_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOY0o2CNjUoQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TradeDemoSeriesDataset(TradeDemoYearByYearDataset):\n",
        "    def __init__(self, root, sequence_len=10, transform=None, pre_transform=None):\n",
        "        self.sequence_len = sequence_len\n",
        "        self.root = root\n",
        "        super().__init__(root, transform, pre_transform)\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return ['traddem_series.pt']\n",
        "\n",
        "    def process(self):\n",
        "        # Read data into Data object.\n",
        "        vdem_nodes = pd.read_csv(os.path.join(self.raw_dir, \"V-Dem-CY-Core-v10.csv\"))\n",
        "\n",
        "        tradhist_timevar_frames = []\n",
        "        for idx in range(1, 4):\n",
        "            tradhist_timevar_frames.append(pd.read_excel(os.path.join(self.raw_dir, \"TRADHIST_GRAVITY_BILATERAL_TIME_VARIANT_{}.xlsx\".format(idx))))\n",
        "        tradhist_timevar = pd.concat(tradhist_timevar_frames)\n",
        "\n",
        "        country_mapping = get_mapping(vdem_nodes, tradhist_timevar)\n",
        "        country_idx_lookup = create_mapping_idx_lookup(country_mapping)\n",
        "\n",
        "        dataset = TradeDemoYearByYearDataset(self.root)\n",
        "\n",
        "        node_dicts = torch.load(self.node_dict)\n",
        "\n",
        "        num_countries = len(country_mapping)\n",
        "        num_initial_features = 5\n",
        "        num_node_features = 2 # include GDP and population data, and democracy data from last year\n",
        "        num_targets = 5 # 5 main indicators of democracy from the VDem dataset\n",
        "        num_edge_features = 7 # Trade flow, current colony relationship, ever a colony, distance, maritime distance, common language, and shared border\n",
        "\n",
        "        all_sequences = []\n",
        "\n",
        "        for start_idx in tqdm.tqdm(enumerate(range(1, len(dataset) - self.sequence_len + 1))):\n",
        "\n",
        "            initial = torch.zeros(num_countries, num_initial_features)\n",
        "            node_dict = node_dicts[start_idx - 1][\"node_mapping\"]\n",
        "            for country_idx, node_idx in node_dict.items():\n",
        "                initial[country_idx, :] = dataset[start_idx - 1].x[node_idx, 2:]\n",
        "\n",
        "            missing_mask = torch.zeros(self.sequence_len, num_countries, num_targets, dtype=torch.float32)\n",
        "            target = torch.zeros(self.sequence_len, num_countries, num_targets, dtype=torch.float32)\n",
        "\n",
        "            sequence_data = []\n",
        "            for year_idx in range(start_idx, start_idx + self.sequence_len):\n",
        "            \n",
        "                x = torch.zeros(num_countries, num_node_features, dtype=torch.float32)\n",
        "                edge_index = torch.zeros(dataset[year_idx].edge_index.shape, dtype=torch.long)\n",
        "\n",
        "                node_dict = node_dicts[start_idx - 1][\"node_mapping\"]\n",
        "                for country_idx, node_idx in node_dict.items():\n",
        "                    x[country_idx, :] = dataset[year_idx].x[node_idx, :]\n",
        "                    edge_index[dataset[year_idx].edge_index == node_idx] = country_idx\n",
        "\n",
        "                sequence_data.append(geo.data.Data(x=x, \n",
        "                                                   edge_index=edge_index, \n",
        "                                                   edge_attr=dataset[year_idx].edge_attr))\n",
        "\n",
        "            sequence = Sequence(initial, sequence_data, missing_mask)\n",
        "            all_sequences.append(sequence)\n",
        "\n",
        "        data, slices = self.collate(all_sequences)\n",
        "        torch.save((data, slices), self.processed_paths[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cjBed_9Op2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequence_len = 10\n",
        "dataset = TradeDemoSeriesDataset(os.path.join('/', 'content', 'drive', 'My Drive', 'projects', 'trade_democratization', 'dataset'), sequence_len=sequence_len)\n",
        "\n",
        "# split into three sets\n",
        "num_train = int(len(dataset) * 0.8)\n",
        "num_val = int(len(dataset) * 0.1)\n",
        "num_test = int(len(dataset) * 0.1)\n",
        "\n",
        "# ensure overlapping sequences don't create val and test set bias\n",
        "train_set = dataset[:num_train - sequence_len]\n",
        "val_set = dataset[num_train:num_train + num_val - sequence_len]\n",
        "test_set = dataset[-num_test:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMuDqfXgQPEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RecurGraphNet(torch.nn.Module):\n",
        "    def __init__(self, node_features, output_size, graph_channels_out, lstm_hidden_size):\n",
        "        super(RecurGraphNet, self).__init__()\n",
        "        # graph convolutional layer to create graph representation\n",
        "        self.conv = GCNConv(node_features, graph_embedding_size)\n",
        "        # lstm to learn sequential patterns\n",
        "        self.lstm = torch.nn.LSTM(graph_embedding_size, lstm_hidden_size)\n",
        "\n",
        "        # initial trainable hidden state for lstm\n",
        "        self.lstm_h_s = torch.nn.Linear(output_size, lstm_hidden_size)\n",
        "        self.lstm_c_s = torch.nn.Linear(output_size, lstm_hidden_size)\n",
        "\n",
        "        # final linear layer to allow full expressivity for regression after tanh activation in lstm\n",
        "        self.final_linear = torch.nn.Linear()\n",
        "\n",
        "    def forward(self, input):\n",
        "        x, initial_state, edge_index, edge_attr = input.x, input.initial_state, input.edge_index, input.edge_attr\n",
        "\n",
        "        # create graph representation\n",
        "        graph_collection = []\n",
        "        for step_idx in range(x.shape[0]):\n",
        "            graph_step = F.relu(self.conv(x[step_idx], edge_index[step_idx], edge_attr[step_idx]))\n",
        "            graph_collection.append(graph_step)\n",
        "        # provide graph representations as sequence to lstm\n",
        "        graph_series = torch.stack(graph_collection)\n",
        "\n",
        "        # recurrent stage\n",
        "        # initial state of lstm is representation of target prior to this sequence\n",
        "        lstm_output = self.lstm(graph_series, (self.lstm_h_s(initial_state), self.lstm_c_s(initial_state)))\n",
        "\n",
        "        # final activation is relu as this is for regression and the metrics of this dataset are all positive\n",
        "        return F.relu(self.final_linear(lstm_output.view(-1, lstm_output.size(2)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}